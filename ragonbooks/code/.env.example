# if you want to run you ai model locally
GEMMA3_BASE_URL=http://localhost:12434/engines/llama.cpp/v1
GEMMA3_EMBEDDING_URL=http://localhost:12434/engines/llama.cpp/v1/embeddings

# OR

# if you want to use open ai
# OPENAI_API_KEY=

# this is required as it will seed you db

# QDRANT_URL=
# QDRANT_API_KEY=
QDRANT_COLLECTION=books
CHUNK_SIZE=1200
CHUNK_OVERLAP=200